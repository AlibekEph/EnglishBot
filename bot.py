import os
import logging
import configparser
from typing import Optional, Dict, Any
import openai
from anthropic import Anthropic
import requests
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

class LLMProvider:
    def __init__(self, config: configparser.ConfigParser):
        self.config = config
        self.openai_client = openai.OpenAI(api_key=config['OpenAI']['API_KEY'])
        self.anthropic_client = Anthropic(api_key=config['Anthropic']['API_KEY'])
        self.default_model = config['LLM']['DEFAULT_MODEL']
        self.local_api_url = config['LocalLLM']['API_URL']
        self.available_local_models = config['LocalLLM']['AVAILABLE_MODELS'].split(',')

    async def check_text(self, text: str) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ—à–∏–±–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è –≤—ã–±—Ä–∞–Ω–Ω—É—é LLM –º–æ–¥–µ–ª—å"""
        model = self.default_model
        
        if model.startswith('gpt'):
            return await self._check_with_openai(text, model)
        elif model.startswith('claude'):
            return await self._check_with_anthropic(text, model)
        elif model in self.available_local_models:
            return await self._check_with_local_model(text, model)
        else:
            raise ValueError(f"Unsupported model: {model}")

    async def _check_with_local_model(self, text: str, model: str) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.post(
                f"{self.local_api_url}/generate",
                json={
                    "text": text,
                    "model": model,
                    "temperature": float(self.config['LocalLLM'].get('TEMPERATURE', 0.7)),
                    "max_tokens": int(self.config['LocalLLM'].get('MAX_TOKENS', 500))
                }
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"Error calling local LLM API: {e}")
            raise

    async def _check_with_openai(self, text: str, model: str) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI"""
        prompt = f"""Analyze this English sentence for grammar and usage errors. 
        If there are errors, provide:
        1. The corrected version
        2. Explanation of the errors in Russian
        3. Confidence score (0.0 to 1.0)
        
        Format the response as JSON:
        {{
            "has_errors": true/false,
            "corrected_text": "corrected version",
            "explanation": "explanation in Russian",
            "confidence": 0.95
        }}
        
        If there are no errors, set has_errors to false and provide a confidence score.
        
        Text to analyze: {text}"""

        response = await self.openai_client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=float(self.config['OpenAI']['TEMPERATURE']),
            max_tokens=int(self.config['OpenAI']['MAX_TOKENS'])
        )
        
        return eval(response.choices[0].message.content)

    async def _check_with_anthropic(self, text: str, model: str) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Anthropic"""
        prompt = f"""Analyze this English sentence for grammar and usage errors. 
        If there are errors, provide:
        1. The corrected version
        2. Explanation of the errors in Russian
        3. Confidence score (0.0 to 1.0)
        
        Format the response as JSON:
        {{
            "has_errors": true/false,
            "corrected_text": "corrected version",
            "explanation": "explanation in Russian",
            "confidence": 0.95
        }}
        
        If there are no errors, set has_errors to false and provide a confidence score.
        
        Text to analyze: {text}"""

        response = await self.anthropic_client.messages.create(
            model=model,
            max_tokens=int(self.config['Anthropic']['MAX_TOKENS']),
            temperature=float(self.config['Anthropic']['TEMPERATURE']),
            messages=[{"role": "user", "content": prompt}]
        )
        
        return eval(response.content[0].text)

class EnglishGrammarBot:
    def __init__(self):
        self.config = configparser.ConfigParser()
        self.config.read('settings.ini')
        self.llm = LLMProvider(self.config)
        self.min_confidence = float(self.config['Bot']['MIN_CONFIDENCE'])

    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
        await update.message.reply_text(
            "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏. "
            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∏ —è –ø—Ä–æ–≤–µ—Ä—é –µ–≥–æ –Ω–∞ –æ—à–∏–±–∫–∏."
        )

    async def help(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
        help_text = """
        –Ø –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏.
        
        –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∏ —è:
        1. –ü—Ä–æ–≤–µ—Ä—é –µ–≥–æ –Ω–∞ –æ—à–∏–±–∫–∏
        2. –ï—Å–ª–∏ –Ω–∞–π–¥—É –æ—à–∏–±–∫–∏, –ø—Ä–µ–¥–ª–æ–∂—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
        3. –û–±—ä—è—Å–Ω—é –æ—à–∏–±–∫–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        
        –ö–æ–º–∞–Ω–¥—ã:
        /start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º
        /help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        await update.message.reply_text(help_text)

    async def process_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        if not update.message or not update.message.text:
            return

        text = update.message.text
        if len(text) > int(self.config['Bot']['MAX_MESSAGE_LENGTH']):
            await update.message.reply_text(
                f"–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ. "
                f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {self.config['Bot']['MAX_MESSAGE_LENGTH']} —Å–∏–º–≤–æ–ª–æ–≤."
            )
            return

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é LLM
            result = await self.llm.check_text(text)
            
            # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result['confidence'] < self.min_confidence:
                return

            if result['has_errors']:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
                response = (
                    f"üîç –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏:\n\n"
                    f"üìù –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç:\n{result['corrected_text']}\n\n"
                    f"üìö –û–±—ä—è—Å–Ω–µ–Ω–∏–µ:\n{result['explanation']}"
                )
                await update.message.reply_text(response)
            
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            await update.message.reply_text(
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è. "
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )

    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
        application = Application.builder().token(self.config['Telegram']['BOT_TOKEN']).build()

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        application.add_handler(CommandHandler("start", self.start))
        application.add_handler(CommandHandler("help", self.help))
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.process_message))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
        application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    load_dotenv()
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    bot = EnglishGrammarBot()
    bot.run() 