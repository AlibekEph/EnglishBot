[Telegram]
BOT_TOKEN = your_bot_token_here

[LLM]
# Available models: gpt-4, gpt-3.5-turbo, claude-3-opus, claude-3-sonnet, llama2-7b, llama2-13b, mistral-7b, mistral-7b-instruct
DEFAULT_MODEL = llama2-7b

[OpenAI]
API_KEY = your_openai_api_key_here
MODEL = gpt-3.5-turbo
TEMPERATURE = 0.7
MAX_TOKENS = 500

[Anthropic]
API_KEY = your_anthropic_api_key_here
MODEL = claude-3-sonnet
TEMPERATURE = 0.7
MAX_TOKENS = 500

[LocalLLM]
# URL локального API сервера
API_URL = http://localhost:8000
# Доступные локальные модели
AVAILABLE_MODELS = llama2-7b,llama2-13b,mistral-7b,mistral-7b-instruct
# Путь к директории с моделями
MODELS_DIR = models
# Количество потоков для обработки
NUM_THREADS = 4
# Размер контекста
CONTEXT_SIZE = 2048

[Bot]
# Minimum confidence score to consider a correction (0.0 to 1.0)
MIN_CONFIDENCE = 0.7
# Language for explanations (ru/en)
EXPLANATION_LANGUAGE = ru
# Maximum message length to process
MAX_MESSAGE_LENGTH = 500 