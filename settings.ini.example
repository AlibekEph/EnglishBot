[Telegram]
BOT_TOKEN = your_bot_token_here

[LLM]
# Available models: gpt-4, gpt-3.5-turbo, claude-3-opus, claude-3-sonnet, llama2-7b, llama2-13b, mistral-7b, mistral-7b-instruct
DEFAULT_MODEL = mistral-7b-instruct-v0.2.gguf
MIN_CONFIDENCE = 0.7
MAX_TOKENS = 256
TEMPERATURE = 0.5

[OpenAI]
API_KEY = your_openai_api_key_here
MODEL = gpt-3.5-turbo
MAX_TOKENS = 150
TEMPERATURE = 0.7
USE_OPENAI = false  # Set to true to use OpenAI instead of local model

[Anthropic]
API_KEY = your_anthropic_api_key_here
MODEL = claude-3-sonnet-20240229

[LocalLLM]
# URL локального API сервера
API_URL = http://localhost:8000
# Доступные локальные модели
AVAILABLE_MODELS = mistral-7b-instruct-v0.2.gguf,llama2-7b-chat.gguf
# Путь к директории с моделями
MODELS_DIR = models
# Количество потоков для обработки
NUM_THREADS = 4
# Размер контекста
CONTEXT_SIZE = 2048

[Bot]
# Minimum confidence score to consider a correction (0.0 to 1.0)
MIN_CONFIDENCE = 0.7
# Language for explanations (ru/en)
EXPLANATION_LANGUAGE = ru
# Maximum message length to process
MAX_MESSAGE_LENGTH = 1000 